{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example Notebook for Bucketizer in PySpark\n",
    "# Reference: https://spark.apache.org/docs/latest/api/python/pyspark.ml.html#pyspark.ml.feature.Bucketizer\n",
    "\n",
    "\"\"\" Bucketizer is used to transform a continuous data into categorical data.\n",
    "The bucket ranges are specified based on the split values.\n",
    "The number of splits can be in even numbers.\n",
    "when using odd number of splits, it will prompt an error\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize the spark session\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the bucketizer feature\n",
    "from pyspark.ml.feature import Bucketizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Bucketizerexample\") \\\n",
    "    .config(\"spark.some.config.option\", \"some-value\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splits has to be in even numbers\n",
    "splits = [-float(\"inf\"), -10.9, -10.1, 0.0, 10.2, 10.5, float(\"inf\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [(-100.9,), (-50.5,), (-10.8,), (0.0,), (10.2,), (10.8,), (102.9,)]\n",
    "df = spark.createDataFrame(data, [\"values\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket = Bucketizer(splits=splits, inputCol=\"values\", outputCol=\"Bucket_value\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucketed_data = bucket.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bucketizer output with 6 buckets\n",
      "+------+------------+\n",
      "|values|Bucket_value|\n",
      "+------+------------+\n",
      "|-100.9|         0.0|\n",
      "| -50.5|         0.0|\n",
      "| -10.8|         1.0|\n",
      "|   0.0|         3.0|\n",
      "|  10.2|         4.0|\n",
      "|  10.8|         5.0|\n",
      "| 102.9|         5.0|\n",
      "+------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Bucketizer output with %d buckets\" % (len(bucket.getSplits())-1))\n",
    "bucketed_data.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
